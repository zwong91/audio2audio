"use client";

import { useEffect, useState } from "react";
import styles from "./page.module.css";

export default function Home() {
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [isRecording, setIsRecording] = useState(true); // true means listening, false means speaking
  const [isPlayingAudio, setIsPlayingAudio] = useState(false); // State to track audio playback
  const [socket, setSocket] = useState<WebSocket | null>(null);

  // åœ¨ç»„ä»¶é¡¶éƒ¨å£°æ˜çŠ¶æ€
  const [audioQueue, setAudioQueue] = useState<Blob[]>([]);
  const [currentAudioElement, setCurrentAudioElement] = useState<HTMLAudioElement | null>(null);

  // éŸ³é¢‘ç®¡ç†å‡½æ•°
  const audioManager = {
    stopCurrentAudio: () => {
      if (currentAudioElement) {
        currentAudioElement.pause();
        currentAudioElement.currentTime = 0;
        URL.revokeObjectURL(currentAudioElement.src);
        setCurrentAudioElement(null);
        setIsPlayingAudio(false);
      }
    },

    playNewAudio: async (audioBlob: Blob) => {
      // åœæ­¢å½“å‰æ’­æ”¾
      audioManager.stopCurrentAudio();

      const audioUrl = URL.createObjectURL(audioBlob);
      const audio = new Audio(audioUrl);
      
      setCurrentAudioElement(audio);
      setIsPlayingAudio(true);
      
      // è®¾ç½®ç»“æŸäº‹ä»¶
      audio.onended = () => {
        URL.revokeObjectURL(audioUrl);
        setCurrentAudioElement(null);
        setIsPlayingAudio(false);
        setIsRecording(true);
      };

      try {
        await audio.play();
      } catch (error) {
        console.error("æ’­æ”¾éŸ³é¢‘å¤±è´¥:", error);
        audioManager.stopCurrentAudio();
      }
    }
  };


  // é¦–å…ˆå®šä¹‰ history çš„ç±»å‹
  type HistoryItem = [string, string]; // [ç”¨æˆ·è¾“å…¥, AIå“åº”]
  type History = HistoryItem[];

  // åœ¨ç»„ä»¶ä¸­ä½¿ç”¨
  const [history, setHistory] = useState<History>([
    ['ä»Šå¤©æ‰“è€è™å—?', 'æ²¡å¦å•Š'],
    ['å¥½ä¹…ä¸è§ä½ è¿˜è®°å¾—å’±ä»¬å¤§å­¦é‚£ä¼šå„¿å—ä½ å¬åˆ°çš„æ˜¯å¼€é¡¹ç›® t t é‚£å¯æ˜¯é£åæ­£èŒ‚çš„å²æœˆå•Šè¿˜è®°å¾—å’±ä¿©çˆ¬é‚£ä¸ªå±±é¡¶çœ‹æ—¥åˆå—å½“æ—¶è®¸å¤šæ„¿æœ›æˆ‘åˆ°ç°åœ¨è¿˜è®°å¾— ğŸ˜”', 
    'å½“ç„¶è®°å¾—ï¼Œé‚£ä¸ªæ—¶å€™çœŸå¼€å¿ƒï¼ä¸€èµ·çˆ¬å±±çš„äº‹çœŸçš„å¾ˆæ€€å¿µï¼Œä½ è¿˜è®°å¾—è®¸çš„æ„¿æœ›å—ï¼Ÿ']
  ]);
  const SOCKET_URL = "wss://gtp.aleopool.cc/stream";

  useEffect(() => {
    // Ensure screen stays awake
    let wakeLock: WakeLockSentinel | null = null;

    async function requestWakeLock() {
      try {
        wakeLock = await navigator.wakeLock.request("screen");
        console.log("Screen wake lock acquired");
      } catch (error) {
        console.error("Failed to acquire wake lock", error);
      }
    }

    requestWakeLock();

    // Clean up the wake lock on unmount
    return () => {
      if (wakeLock) {
        wakeLock.release().then(() => {
          console.log("Screen wake lock released");
        }).catch((error) => {
          console.error("Failed to release wake lock", error);
        });
      }
    };
  }, []); // Only run on mount and unmount

  useEffect(() => {
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
        setMediaRecorder(new MediaRecorder(stream));
      }).catch((error) => {
        console.error("Error accessing media devices.", error);
      });
    } else {
      console.error("Media devices API not supported.");
    }
  }, []); // Setup mediaRecorder initially

  useEffect(() => {
    const script = document.createElement("script");
    script.src = "https://www.WebRTC-Experiment.com/RecordRTC.js";
    script.onload = () => {
      const RecordRTC = (window as any).RecordRTC;
      const StereoAudioRecorder = (window as any).StereoAudioRecorder;
      let currentAudioElement: HTMLAudioElement | null = null; // Track the current playing audio element

      if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
          let websocket: WebSocket | null = null;

          // WebSocket reconnect logic
          const reconnectWebSocket = () => {
            if (websocket) websocket.close(); // Close existing WebSocket if it exists
            websocket = new WebSocket(SOCKET_URL);
            setSocket(websocket);

            websocket.onopen = () => {
              console.log("client connected to websocket");

              const recorder = new RecordRTC(stream, {
                type: 'audio',
                recorderType: StereoAudioRecorder,
                mimeType: 'audio/wav',
                timeSlice: 500,
                desiredSampRate: 16000,
                numberOfAudioChannels: 1,
                ondataavailable: (blob: Blob) => {
                  if (blob.size > 0) {
                    const reader = new FileReader();
                    reader.onloadend = () => {
                      if (reader.result) {
                        // Convert ArrayBuffer to Base64
                        const base64data = arrayBufferToBase64(reader.result as ArrayBuffer);

                        // Prepare the data to be sent
                        const dataToSend = [
                          history, // Include the stored history
                          "xiaoxiao", // The user identifier or other identifier
                          base64data // The base64 encoded audio data
                        ];
                        const jsonData = JSON.stringify(dataToSend);

                        // Safe check to ensure websocket is not null
                        if (websocket) {
                          websocket.send(jsonData);
                        } else {
                          console.error("WebSocket is null, cannot send data.");
                        }
                      } else {
                        console.error("FileReader result is null");
                      }
                    };
                    reader.readAsArrayBuffer(blob); // Read as ArrayBuffer
                  }
                }
              });

              recorder.startRecording();
            };

            websocket.onmessage = (event) => {
              setIsRecording(false); // Stop recording when receiving message
              setIsPlayingAudio(true); // Start playing audio
            
              try {
                const jsonData = JSON.parse(event.data);
                const audioBase64 = jsonData["stream"];
                
                const receivedHistory = jsonData["history"]; // Extract the history
                if (Array.isArray(receivedHistory)) {
                  // ç¡®ä¿æ”¶åˆ°çš„å†å²è®°å½•æ˜¯äºŒç»´æ•°ç»„ç»“æ„
                  const formattedHistory = receivedHistory.map(item => 
                    Array.isArray(item) ? item : [item[0], item[1]]
                  );
                  setHistory(formattedHistory);
                }
                if (!audioBase64) {
                  console.error("No audio stream data received");
                  return;
                }

              // è½¬æ¢éŸ³é¢‘æ•°æ®
              const binaryString = atob(audioBase64);
              const bytes = new Uint8Array(binaryString.length);
              bytes.set(Uint8Array.from(binaryString, c => c.charCodeAt(0)));
              const audioBlob = new Blob([bytes], { type: "audio/wav" });

              // æ’­æ”¾æ–°éŸ³é¢‘
              audioManager.playNewAudio(audioBlob);
            
              } catch (error) {
                console.error("Error processing WebSocket message:", error);
              }
            };

            websocket.onclose = () => {
              console.log("WebSocket connection closed, attempting to reconnect...");
              setTimeout(reconnectWebSocket, 5000); // Retry after 5 seconds
            };

            websocket.onerror = (error) => {
              console.error("WebSocket error:", error);
              websocket?.close();
            };
          };

          reconnectWebSocket(); // Initial connection attempt
        }).catch((error) => {
          console.error("Error with getUserMedia", error);
        });
      }
    };
    document.body.appendChild(script);

    // Cleanup on component unmount
    return () => {
      if (socket) {
        socket.close();
      }
    };
  }, [mediaRecorder]);

  useEffect(() => {
    if (mediaRecorder && mediaRecorder.state !== "inactive") {
      if (isRecording) {
        mediaRecorder.resume();
      } else {
        mediaRecorder.pause();
      }
    }
  }, [isRecording, mediaRecorder]);

  // Helper function to convert ArrayBuffer to Base64
  function arrayBufferToBase64(arrayBuffer: ArrayBuffer): string {
    let binary = '';
    const uint8Array = new Uint8Array(arrayBuffer);
    const len = uint8Array.length;
    for (let i = 0; i < len; i++) {
      binary += String.fromCharCode(uint8Array[i]);
    }
    return btoa(binary); // Convert binary string to base64
  }

  return (
    <>
      <div className={styles.title}>AudioChat - your voice AI assistant</div>
      <div className={styles["center-vertical"]}>
        <div
          className={`${styles["speaker-indicator"]} ${styles["you-speaking"]} ${isRecording && !isPlayingAudio ? styles.pulsate : ""}`}
        ></div>
        <br />
        <div>{isRecording && !isPlayingAudio ? "Listening..." : "Speaking..."}</div>
        <br />
        <div
          className={`${styles["speaker-indicator"]} ${styles["machine-speaking"]} ${!isRecording && isPlayingAudio ? styles.pulsate : ""}`}
        ></div>
      </div>
    </>
  );
}
